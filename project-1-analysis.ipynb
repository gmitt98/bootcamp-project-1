{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis part 1: interest rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cleaned data/total_market_data_merged.csv')\n",
    "df = df.drop(['Unnamed: 0', \"YEAR_x\", \"YEAR_y\", 'DATE'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Five-Digit ZIP Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>Annual Change (%)</th>\n",
       "      <th>HPI</th>\n",
       "      <th>HPI from 2012</th>\n",
       "      <th>HPI with 2012 base</th>\n",
       "      <th>normalized_sale_price</th>\n",
       "      <th>RECESSION_FLAG</th>\n",
       "      <th>avg_rate_for_year</th>\n",
       "      <th>Median_hh_income</th>\n",
       "      <th>Year_Avg_Unempl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>1984</td>\n",
       "      <td>.</td>\n",
       "      <td>100.00</td>\n",
       "      <td>279.95</td>\n",
       "      <td>0.357207</td>\n",
       "      <td>58369.688570</td>\n",
       "      <td>0</td>\n",
       "      <td>10.225</td>\n",
       "      <td>55828</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002.0</td>\n",
       "      <td>1984</td>\n",
       "      <td>15.40</td>\n",
       "      <td>115.40</td>\n",
       "      <td>348.54</td>\n",
       "      <td>0.331095</td>\n",
       "      <td>91121.681896</td>\n",
       "      <td>0</td>\n",
       "      <td>10.225</td>\n",
       "      <td>55828</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1020.0</td>\n",
       "      <td>1984</td>\n",
       "      <td>14.40</td>\n",
       "      <td>114.40</td>\n",
       "      <td>296.68</td>\n",
       "      <td>0.385601</td>\n",
       "      <td>54643.995979</td>\n",
       "      <td>0</td>\n",
       "      <td>10.225</td>\n",
       "      <td>55828</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1027.0</td>\n",
       "      <td>1984</td>\n",
       "      <td>24.50</td>\n",
       "      <td>124.50</td>\n",
       "      <td>400.14</td>\n",
       "      <td>0.311141</td>\n",
       "      <td>67051.045930</td>\n",
       "      <td>0</td>\n",
       "      <td>10.225</td>\n",
       "      <td>55828</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1028.0</td>\n",
       "      <td>1984</td>\n",
       "      <td>15.12</td>\n",
       "      <td>197.78</td>\n",
       "      <td>537.26</td>\n",
       "      <td>0.368127</td>\n",
       "      <td>82988.087351</td>\n",
       "      <td>0</td>\n",
       "      <td>10.225</td>\n",
       "      <td>55828</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Five-Digit ZIP Code  Year Annual Change (%)     HPI  HPI from 2012  \\\n",
       "0               1001.0  1984                 .  100.00         279.95   \n",
       "1               1002.0  1984             15.40  115.40         348.54   \n",
       "2               1020.0  1984             14.40  114.40         296.68   \n",
       "3               1027.0  1984             24.50  124.50         400.14   \n",
       "4               1028.0  1984             15.12  197.78         537.26   \n",
       "\n",
       "   HPI with 2012 base  normalized_sale_price  RECESSION_FLAG  \\\n",
       "0            0.357207           58369.688570               0   \n",
       "1            0.331095           91121.681896               0   \n",
       "2            0.385601           54643.995979               0   \n",
       "3            0.311141           67051.045930               0   \n",
       "4            0.368127           82988.087351               0   \n",
       "\n",
       "   avg_rate_for_year  Median_hh_income  Year_Avg_Unempl  \n",
       "0             10.225             55828              7.7  \n",
       "1             10.225             55828              7.7  \n",
       "2             10.225             55828              7.7  \n",
       "3             10.225             55828              7.7  \n",
       "4             10.225             55828              7.7  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4/5/bonus: machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the data I'm going to make an annual change % with: zip code, year, recession flag, avg rate\n",
    "new_data = np.array([[97405, 2023, 0, 5.0, 71000, 4],\n",
    "                     [97405, 2024, 0, 5.0, 71000, 5],\n",
    "                     [97405, 2025, 0, 5.0, 71000, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset with no missing annual change values - just drop them\n",
    "\n",
    "dfml = df[df[\"Annual Change (%)\"].notna()]\n",
    "dfml=dfml[~dfml.isin([\".\"]).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define my target var\n",
    "mltarget = dfml[\"Annual Change (%)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five-Digit ZIP Code    float64\n",
      "Year                     int64\n",
      "RECESSION_FLAG           int64\n",
      "avg_rate_for_year      float64\n",
      "Median_hh_income         int64\n",
      "Year_Avg_Unempl        float64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hl/p3c4xh5x4nv00kvc7sckx1040000gn/T/ipykernel_86899/1646799607.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mlfeatures['Year'] = pd.to_datetime(mlfeatures['Year'], format='%Y')\n",
      "/var/folders/hl/p3c4xh5x4nv00kvc7sckx1040000gn/T/ipykernel_86899/1646799607.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mlfeatures['Year'] = pd.to_datetime(mlfeatures['Year']).dt.year\n"
     ]
    }
   ],
   "source": [
    "# define my features\n",
    "mlfeatures = dfml[[\"Five-Digit ZIP Code\", \"Year\", \"RECESSION_FLAG\", \"avg_rate_for_year\", \"Median_hh_income\", \"Year_Avg_Unempl\"]]\n",
    "mlfeatures['Year'] = pd.to_datetime(mlfeatures['Year'], format='%Y')\n",
    "mlfeatures['Year'] = pd.to_datetime(mlfeatures['Year']).dt.year\n",
    "#mlfeatures.set_index('Year', inplace=True)\n",
    "print(mlfeatures.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Five-Digit ZIP Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>RECESSION_FLAG</th>\n",
       "      <th>avg_rate_for_year</th>\n",
       "      <th>Median_hh_income</th>\n",
       "      <th>Year_Avg_Unempl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002.0</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "      <td>10.225</td>\n",
       "      <td>55828</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1020.0</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "      <td>10.225</td>\n",
       "      <td>55828</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1027.0</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "      <td>10.225</td>\n",
       "      <td>55828</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1028.0</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "      <td>10.225</td>\n",
       "      <td>55828</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1040.0</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "      <td>10.225</td>\n",
       "      <td>55828</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Five-Digit ZIP Code  Year  RECESSION_FLAG  avg_rate_for_year  \\\n",
       "1               1002.0  1984               0             10.225   \n",
       "2               1020.0  1984               0             10.225   \n",
       "3               1027.0  1984               0             10.225   \n",
       "4               1028.0  1984               0             10.225   \n",
       "5               1040.0  1984               0             10.225   \n",
       "\n",
       "   Median_hh_income  Year_Avg_Unempl  \n",
       "1             55828              7.7  \n",
       "2             55828              7.7  \n",
       "3             55828              7.7  \n",
       "4             55828              7.7  \n",
       "5             55828              7.7  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414660, 6)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlfeatures.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of mlfeatures_train: (331728, 6)\n",
      "Shape of mltarget_train: (331728,)\n",
      "Shape of mlfeatures_test: (82932, 6)\n",
      "Shape of mltarget_test: (82932,)\n",
      "Shape of mlfeatures_train_date: (364739, 6)\n",
      "Shape of mltarget_train_date: (364739,)\n",
      "Shape of mlfeatures_test_date: (49921, 6)\n",
      "Shape of mltarget_test_date: (49921,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# First using random\n",
    "mlfeatures_train, mlfeatures_test, mltarget_train, mltarget_test = train_test_split(mlfeatures, mltarget, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"Shape of mlfeatures_train:\", mlfeatures_train.shape)\n",
    "print(\"Shape of mltarget_train:\", mltarget_train.shape)\n",
    "print(\"Shape of mlfeatures_test:\", mlfeatures_test.shape)\n",
    "print(\"Shape of mltarget_test:\", mltarget_test.shape)\n",
    "\n",
    "# Second split: using dates\n",
    "dfmltrim = dfml[[\"Five-Digit ZIP Code\", \"Year\", \"RECESSION_FLAG\", \"avg_rate_for_year\",'Median_hh_income','Year_Avg_Unempl', 'Annual Change (%)']]\n",
    "train_date_df = dfmltrim[dfmltrim['Year'] < 2019]\n",
    "test_date_df = dfmltrim[dfmltrim['Year'] >= 2019]\n",
    "\n",
    "# Separate features and target variables\n",
    "mlfeatures_train_date = train_date_df.drop('Annual Change (%)', axis=1)\n",
    "mltarget_train_date = train_date_df['Annual Change (%)']\n",
    "mlfeatures_test_date = test_date_df.drop('Annual Change (%)', axis=1)\n",
    "mltarget_test_date = test_date_df['Annual Change (%)']\n",
    "\n",
    "print(\"Shape of mlfeatures_train_date:\", mlfeatures_train_date.shape)\n",
    "print(\"Shape of mltarget_train_date:\", mltarget_train_date.shape)\n",
    "print(\"Shape of mlfeatures_test_date:\", mlfeatures_test_date.shape)\n",
    "print(\"Shape of mltarget_test_date:\", mltarget_test_date.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Five-Digit ZIP Code', 'Year', 'RECESSION_FLAG', 'avg_rate_for_year',\n",
       "       'Median_hh_income', 'Year_Avg_Unempl'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlfeatures_train.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a Linear Regression model for each\n",
    "lr_model = LinearRegression()\n",
    "lr_model_date = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "lr_model.fit(mlfeatures_train, mltarget_train)\n",
    "lr_model_date.fit(mlfeatures_train_date, mltarget_train_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80-20 split results\n",
      "Mean Squared Error: 46.86627544855477\n",
      "Root Mean Squared Error: 6.845894788013819\n",
      "R-squared: 0.21805482735883686\n",
      "date-based results\n",
      "Mean Squared Error: 46.86627544855477\n",
      "Root Mean Squared Error: 6.845894788013819\n",
      "R-squared: 0.21805482735883686\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Make predictions on the testing data\n",
    "mltarget_pred = lr_model.predict(mlfeatures_test) # 80/20 split\n",
    "mltarget_date_pred = lr_model_date.predict(mlfeatures_test_date) # date-based split\n",
    "\n",
    "print(\"80-20 split results\")\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(mltarget_test, mltarget_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "# Compute the root mean squared error\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(mltarget_test, mltarget_pred)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "\n",
    "print(\"date-based results\")\n",
    "mse_date = mean_squared_error(mltarget_test, mltarget_pred)\n",
    "print(\"Mean Squared Error:\", mse_date)\n",
    "# Compute the root mean squared error\n",
    "rmse_date = np.sqrt(mse_date)\n",
    "print(\"Root Mean Squared Error:\", rmse_date)\n",
    "# Compute the R-squared score\n",
    "r2_date = r2_score(mltarget_test_date, mltarget_date_pred)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Annual Change (%): [9.35804486 9.31318181 9.26831877]\n",
      "Predicted Annual Change (%): [5.65806987 5.55785922 5.45764857]  based on date-split train test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/galenmittermann/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/galenmittermann/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TESTING THE MODEL OUT\n",
    "\n",
    "\n",
    "# Use the trained model to make predictions for the new dataset\n",
    "predictions = lr_model.predict(new_data)\n",
    "predictions_date = lr_model_date.predict(new_data)\n",
    "# Print the predicted annual change (%) for each year\n",
    "print(\"Predicted Annual Change (%):\", predictions)\n",
    "print(\"Predicted Annual Change (%):\", predictions_date, \" based on date-split train test\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results based on 80-20 split\n",
      "Mean Squared Error: 27.434710029783623\n",
      "Root Mean Squared Error: 5.237815387142203\n",
      "R-squared: 0.542262770717767\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "# Fit the model to the training data\n",
    "rf_model.fit(mlfeatures_train, mltarget_train)\n",
    "\n",
    "print(\"Results based on 80-20 split\")\n",
    "mltarget_pred = rf_model.predict(mlfeatures_test)\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(mltarget_test, mltarget_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "# Compute the root mean squared error\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(mltarget_test, mltarget_pred)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results based on date split\n",
      "Mean Squared Error: 74.11522006213326\n",
      "Root Mean Squared Error: 8.609019692283974\n",
      "R-squared: -0.3623447822636039\n"
     ]
    }
   ],
   "source": [
    "# Date based split\n",
    "# Create a Random Forest model\n",
    "rf_model_date = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "# Fit the model to the training data\n",
    "rf_model_date.fit(mlfeatures_train_date, mltarget_train_date)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "print(\"Results based on date split\")\n",
    "mltarget_date_pred = rf_model_date.predict(mlfeatures_test_date)\n",
    "# Compute the mean squared error\n",
    "mse_date = mean_squared_error(mltarget_test_date, mltarget_date_pred)\n",
    "print(\"Mean Squared Error:\", mse_date)\n",
    "# Compute the root mean squared error\n",
    "rmse_date = np.sqrt(mse_date)\n",
    "print(\"Root Mean Squared Error:\", rmse_date)\n",
    "# Compute the R-squared score\n",
    "r2_date = r2_score(mltarget_test_date, mltarget_date_pred)\n",
    "print(\"R-squared:\", r2_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Annual Change (%): [16.50425 16.50425 16.50425]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/galenmittermann/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TESTING THE RANDOM SPLIT MODEL OUT\n",
    "\n",
    "\n",
    "# Use the trained model to make predictions for the new dataset\n",
    "predictions = rf_model.predict(new_data)\n",
    "\n",
    "# Print the predicted annual change (%) for each year\n",
    "print(\"Predicted Annual Change (%):\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Annual Change (%): [5.47745 5.47745 5.47745]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/galenmittermann/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TESTING THE DATE MODEL OUT\n",
    "\n",
    "\n",
    "# Use the trained model to make predictions for the new dataset\n",
    "predictions = rf_model_date.predict(new_data)\n",
    "\n",
    "# Print the predicted annual change (%) for each year\n",
    "print(\"Predicted Annual Change (%):\", predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 25.785538313017287\n",
      "Root Mean Squared Error: 5.077946269213301\n",
      "R-squared: 0.5697785451299523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Create a Gradient Boosting Regressor model\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "gb_model.fit(mlfeatures_train, mltarget_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "mltarget_pred = gb_model.predict(mlfeatures_test)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(mltarget_test, mltarget_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Compute the root mean squared error\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(mltarget_test, mltarget_pred)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 25.785538313017287\n",
      "Root Mean Squared Error: 5.077946269213301\n",
      "R-squared: -0.18059401467350544\n"
     ]
    }
   ],
   "source": [
    "# Create a Gradient Boosting Regressor model\n",
    "gb_model_date = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "gb_model_date.fit(mlfeatures_train_date, mltarget_train_date)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "mltarget_pred_date = gb_model_date.predict(mlfeatures_test_date)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse_date = mean_squared_error(mltarget_test_date, mltarget_pred_date)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Compute the root mean squared error\n",
    "rmse_date = np.sqrt(mse_date)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(mltarget_test_date, mltarget_pred_date)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Annual Change (%): [14.00218644 14.00218644 14.00218644]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/galenmittermann/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TESTING THE SPLIT MODEL OUT\n",
    "\n",
    "# Use the trained model to make predictions for the new dataset\n",
    "predictions = gb_model.predict(new_data)\n",
    "\n",
    "# Print the predicted annual change (%) for each year\n",
    "print(\"Predicted Annual Change (%):\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Annual Change (%): [4.94158974 4.94158974 4.94158974]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/galenmittermann/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TESTING THE DATE MODEL OUT\n",
    "\n",
    "\n",
    "# Use the trained model to make predictions for the new dataset\n",
    "predictions_date = gb_model_date.predict(new_data)\n",
    "\n",
    "# Print the predicted annual change (%) for each year\n",
    "print(\"Predicted Annual Change (%):\", predictions_date)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting regressor to combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 25.958450006126125\n",
      "Root Mean Squared Error: 5.094943572418258\n",
      "R-squared: 0.5668935822771204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# Create the voting regressor\n",
    "voting_model = VotingRegressor([('rf', rf_model), ('gb', gb_model), ('lr', lr_model)])\n",
    "\n",
    "# Fit the voting regressor to the training data\n",
    "voting_model.fit(mlfeatures_train, mltarget_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "mltarget_pred = voting_model.predict(mlfeatures_test)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(mltarget_test, mltarget_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Compute the root mean squared error\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "# Compute the R-squared score\n",
    "r2 = r2_score(mltarget_test, mltarget_pred)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/galenmittermann/Documents/GitHub/bootcamp-project-1/project-1-analysis.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/galenmittermann/Documents/GitHub/bootcamp-project-1/project-1-analysis.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m voting_model_date\u001b[39m.\u001b[39mfit(mlfeatures_train_date, mltarget_train_date)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/galenmittermann/Documents/GitHub/bootcamp-project-1/project-1-analysis.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Make predictions on the testing data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/galenmittermann/Documents/GitHub/bootcamp-project-1/project-1-analysis.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m mltarget_pred_date \u001b[39m=\u001b[39m voting_model_date\u001b[39m.\u001b[39;49mpredict(mlfeatures_test_date)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galenmittermann/Documents/GitHub/bootcamp-project-1/project-1-analysis.ipynb#X44sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Compute the mean squared error\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galenmittermann/Documents/GitHub/bootcamp-project-1/project-1-analysis.ipynb#X44sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m mse_date \u001b[39m=\u001b[39m mean_squared_error(mltarget_test_date, mltarget_pred_date)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:548\u001b[0m, in \u001b[0;36mVotingRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[39m\"\"\"Predict regression target for X.\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \n\u001b[1;32m    534\u001b[0m \u001b[39mThe predicted regression target of an input sample is computed as the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[39m    The predicted values.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    547\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 548\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39maverage(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(X), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, weights\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_weights_not_none)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:60\u001b[0m, in \u001b[0;36m_BaseVoting._predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m     59\u001b[0m     \u001b[39m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray([est\u001b[39m.\u001b[39mpredict(X) \u001b[39mfor\u001b[39;00m est \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_])\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:60\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m     59\u001b[0m     \u001b[39m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray([est\u001b[39m.\u001b[39;49mpredict(X) \u001b[39mfor\u001b[39;00m est \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_])\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:984\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[39m# Parallel loop\u001b[39;00m\n\u001b[1;32m    983\u001b[0m lock \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mLock()\n\u001b[0;32m--> 984\u001b[0m Parallel(\n\u001b[1;32m    985\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    986\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    987\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(require\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msharedmem\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    988\u001b[0m )(\n\u001b[1;32m    989\u001b[0m     delayed(_accumulate_prediction)(e\u001b[39m.\u001b[39;49mpredict, X, [y_hat], lock)\n\u001b[1;32m    990\u001b[0m     \u001b[39mfor\u001b[39;49;00m e \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimators_\n\u001b[1;32m    991\u001b[0m )\n\u001b[1;32m    993\u001b[0m y_hat \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_)\n\u001b[1;32m    995\u001b[0m \u001b[39mreturn\u001b[39;00m y_hat\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:640\u001b[0m, in \u001b[0;36m_accumulate_prediction\u001b[0;34m(predict, X, out, lock)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_accumulate_prediction\u001b[39m(predict, X, out, lock):\n\u001b[1;32m    634\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[39m    This is a utility function for joblib's Parallel.\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \n\u001b[1;32m    637\u001b[0m \u001b[39m    It can't go locally in ForestClassifier or ForestRegressor, because joblib\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[39m    complains that it cannot pickle it when placed there.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 640\u001b[0m     prediction \u001b[39m=\u001b[39m predict(X, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    641\u001b[0m     \u001b[39mwith\u001b[39;00m lock:\n\u001b[1;32m    642\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:468\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    466\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    467\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[0;32m--> 468\u001b[0m proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[1;32m    469\u001b[0m n_samples \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    471\u001b[0m \u001b[39m# Classification\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create the voting regressor\n",
    "voting_model_date = VotingRegressor([('rf', rf_model_date), ('gb', gb_model_date), ('lr', lr_model_date)])\n",
    "\n",
    "# Fit the voting regressor to the training data\n",
    "voting_model_date.fit(mlfeatures_train_date, mltarget_train_date)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "mltarget_pred_date = voting_model_date.predict(mlfeatures_test_date)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse_date = mean_squared_error(mltarget_test_date, mltarget_pred_date)\n",
    "print(\"Mean Squared Error:\", mse_date)\n",
    "\n",
    "# Compute the root mean squared error\n",
    "rmse_date = np.sqrt(mse_date)\n",
    "print(\"Root Mean Squared Error:\", rmse_date)\n",
    "\n",
    "# Compute the R-squared score\n",
    "r2_date = r2_score(mltarget_test_date, mltarget_pred_date)\n",
    "print(\"R-squared:\", r2_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Annual Change (%): [15.59551466 15.68364844 15.77178221]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/galenmittermann/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/galenmittermann/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/galenmittermann/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TESTING THE MODEL OUT\n",
    "\n",
    "# Create a new dataset with the desired feature values\n",
    "new_data = np.array([[97405, 2023, 0, 5.0],\n",
    "                     [97405, 2024, 0, 5.0],\n",
    "                     [97405, 2025, 0, 5.0]])\n",
    "\n",
    "# Use the trained model to make predictions for the new dataset\n",
    "predictions = voting_model.predict(new_data)\n",
    "\n",
    "# Print the predicted annual change (%) for each year\n",
    "print(\"Predicted Annual Change (%):\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Annual Change (%): [7.88366927 7.91741429 7.95115931]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/galenmittermann/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/galenmittermann/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/galenmittermann/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TESTING THE MODEL OUT\n",
    "\n",
    "# Use the trained model to make predictions for the new dataset\n",
    "predictions_date = voting_model_date.predict(new_data)\n",
    "\n",
    "# Print the predicted annual change (%) for each year\n",
    "print(\"Predicted Annual Change (%):\", predictions_date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
